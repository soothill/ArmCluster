IOR-3.3.0+dev: MPI Coordinated Test of Parallel I/O
Began               : Sat Jun 27 09:17:28 2020
Command line        : /IO500/bin/ior -w -a POSIX -t 2m -v -b 9920000m -F -i 1 -C -Q 1 -g -G 27 -k -e -o /mnt/cephfs/datafiles/2020.06.27-09.06.38-scr/ior_easy/ior_file_easy -O stoneWallingStatusFile=/mnt/cephfs/datafiles/2020.06.27-09.06.38-scr/ior_easy/stonewall -O stoneWallingWearOut=1 -D 300
Machine             : Linux sr650-1
Start time skew across all tasks: 321.23 sec
TestID              : 0
StartTime           : Sat Jun 27 09:17:28 2020
Path                : /mnt/cephfs/datafiles/2020.06.27-09.06.38-scr/ior_easy
FS                  : 32.4 TiB   Used FS: 12.1%   Inodes: 7.4 Mi   Used Inodes: 100.0%
Participating tasks: 200
Using reorderTasks '-C' (useful to avoid read cache in client)

Options: 
api                 : POSIX
apiVersion          : 
test filename       : /mnt/cephfs/datafiles/2020.06.27-09.06.38-scr/ior_easy/ior_file_easy
access              : file-per-process
type                : independent
segments            : 1
ordering in a file  : sequential
ordering inter file : constant task offset
task offset         : 1
nodes               : 10
tasks               : 200
clients per node    : 20
repetitions         : 1
xfersize            : 2 MiB
blocksize           : 9.46 TiB
aggregate filesize  : 1892.09 TiB
stonewallingTime    : 300
stoneWallingWearOut : 1

Results: 

access    bw(MiB/s)  IOPS       Latency(s)  block(KiB) xfer(KiB)  open(s)    wr/rd(s)   close(s)   total(s)   iter
------    ---------  ----       ----------  ---------- ---------  --------   --------   --------   --------   ----
Commencing write performance test: Sat Jun 27 09:17:28 2020
[mpiexec@sr630-1] Sending Ctrl-C to processes as requested
[mpiexec@sr630-1] Press Ctrl-C again to force abort
