IOR-3.3.0+dev: MPI Coordinated Test of Parallel I/O
Began               : Mon Jun 22 04:02:40 2020
Command line        : /IO500/io500-app/bin/ior -w -a POSIX -t 2m -v -b 9920000m -F -i 1 -C -Q 1 -g -G 27 -k -e -o /mnt/cephfs/datafiles/2020.06.22-04.08.58-scr/ior_easy/ior_file_easy -O stoneWallingStatusFile=/mnt/cephfs/datafiles/2020.06.22-04.08.58-scr/ior_easy/stonewall -O stoneWallingWearOut=1 -D 300
Machine             : Linux sr650-1
Start time skew across all tasks: 321.28 sec
TestID              : 0
StartTime           : Mon Jun 22 04:02:40 2020
Path                : /mnt/cephfs/datafiles/2020.06.22-04.08.58-scr/ior_easy
FS                  : 31.3 TiB   Used FS: 24.5%   Inodes: 1.9 Mi   Used Inodes: 100.0%
Participating tasks: 160
Using reorderTasks '-C' (useful to avoid read cache in client)

Options: 
api                 : POSIX
apiVersion          : 
test filename       : /mnt/cephfs/datafiles/2020.06.22-04.08.58-scr/ior_easy/ior_file_easy
access              : file-per-process
type                : independent
segments            : 1
ordering in a file  : sequential
ordering inter file : constant task offset
task offset         : 1
nodes               : 10
tasks               : 160
clients per node    : 16
repetitions         : 1
xfersize            : 2 MiB
blocksize           : 9.46 TiB
aggregate filesize  : 1513.67 TiB
stonewallingTime    : 300
stoneWallingWearOut : 1

Results: 

access    bw(MiB/s)  IOPS       Latency(s)  block(KiB) xfer(KiB)  open(s)    wr/rd(s)   close(s)   total(s)   iter
------    ---------  ----       ----------  ---------- ---------  --------   --------   --------   --------   ----
Commencing write performance test: Mon Jun 22 04:02:41 2020
[mpiexec@sr630-1] Sending Ctrl-C to processes as requested
[mpiexec@sr630-1] Press Ctrl-C again to force abort
